{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conala-UnTokenized.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahafp/Conala-Challenge/blob/master/Conala_UnTokenized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieK0oXM5CwsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import re\n",
        "import torch\n",
        "import numpy\n",
        "from torch import autograd, nn, optim\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fZ8dG5kC4qX",
        "colab_type": "code",
        "outputId": "a2d0701a-a064-4a8e-dcdd-5f10b40a8aaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns_yiAEGC7GM",
        "colab_type": "code",
        "outputId": "39e5c2aa-e97f-4913-9d6c-87d4349afd46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eUrGetvHVUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STKQU7xMC9a3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VocabIntent :\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQP-ykdwDF_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VocabCode:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        # for word in re.split('([^a-zA-Z0-9 ])',sentence):\n",
        "        #   if word is not '':\n",
        "        self.addWord(sentence)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zme_042tDJDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def orginize_data(data_type):\n",
        "  json_data = '/content/drive/My Drive/conala/' + data_type  \n",
        "  path = open(json_data, \"r\")\n",
        "  data = json.load(path)\n",
        "  pairs=[]\n",
        "  for dic in data:\n",
        "      if dic[\"rewritten_intent\"] is None:\n",
        "          continue\n",
        "      pairs.append([dic[\"rewritten_intent\"], dic[\"snippet\"]])\n",
        "  orginize_data_mined(pairs)\n",
        "\n",
        "def orginize_data_mined(pairs):\n",
        "  json_data = 'C:\\\\Users\\\\SPariente\\\\Desktop\\\\Work\\\\Dev\\\\Python\\\\NLP\\\\Conala\\\\conala-corpus\\\\conala-mined.jsonl'\n",
        "  with open(json_data, 'r', encoding='utf-8') as f:\n",
        "      for line in f:\n",
        "          j_line = json.loads(line.rstrip('\\n|\\r'))\n",
        "          pairs.append([j_line[\"intent\"], j_line[\"snippet\"]])\n",
        "  return pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW5f2MoQDLg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(vocab1_name, vocab2_name, data_type):\n",
        "  pairs=orginize_data(data_type=data_type)\n",
        "  intent_vocab=VocabIntent(vocab1_name)\n",
        "  code_vocab=VocabCode(vocab2_name)\n",
        "\n",
        "  for pair in pairs:\n",
        "    intent_vocab.addSentence(pair[0])\n",
        "    code_vocab.addSentence(pair[1])\n",
        "  \n",
        "  return intent_vocab, code_vocab, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR6w2QLIDPwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_lang, output_lang, pairs= prepare_data('intent', 'code', 'conala-train.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjYTuOnfF-F6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx1T18xpGIof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeS38kFuGJmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5DPvrokGQrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def c_indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[sentence]]\n",
        "\n",
        "def tensorFromSentence(lang, sentence, key):\n",
        "    if key is 'intent':\n",
        "      indexes = indexesFromSentence(lang, sentence)\n",
        "      indexes.append(EOS_token)\n",
        "    else:\n",
        "      indexes = c_indexesFromSentence(lang, sentence)\n",
        "      indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0], 'intent')\n",
        "    target_tensor =tensorFromSentence(output_lang, pair[1], 'code')\n",
        "    return (input_tensor, target_tensor)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBvQ9BydGVQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeLIxUwAGaYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRnWSrgZGd6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "      showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLwVGq_AGgmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvhLCGAIGkSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence, 'intent')\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niS62EYRGrMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence.strip(' '))\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-uwZYvZGuag",
        "colab_type": "code",
        "outputId": "343ceec2-a765-461e-d928-ccf0d1abf66e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 5s (- 73m 30s) (100 0%) 4.9756\n",
            "0m 7s (- 44m 1s) (200 0%) 4.1142\n",
            "0m 8s (- 34m 5s) (300 0%) 3.9351\n",
            "0m 9s (- 29m 13s) (400 0%) 3.8974\n",
            "0m 10s (- 26m 13s) (500 0%) 3.8946\n",
            "0m 11s (- 24m 20s) (600 0%) 3.9126\n",
            "0m 12s (- 22m 56s) (700 0%) 3.9114\n",
            "0m 14s (- 21m 51s) (800 1%) 3.8960\n",
            "0m 15s (- 21m 6s) (900 1%) 3.8851\n",
            "0m 16s (- 20m 24s) (1000 1%) 3.8685\n",
            "0m 17s (- 19m 55s) (1100 1%) 3.9122\n",
            "0m 19s (- 19m 44s) (1200 1%) 3.8965\n",
            "0m 20s (- 19m 18s) (1300 1%) 3.8879\n",
            "0m 21s (- 18m 55s) (1400 1%) 3.9068\n",
            "0m 22s (- 18m 39s) (1500 2%) 3.8795\n",
            "0m 23s (- 18m 20s) (1600 2%) 3.8369\n",
            "0m 25s (- 18m 3s) (1700 2%) 3.8541\n",
            "0m 26s (- 17m 52s) (1800 2%) 3.8901\n",
            "0m 27s (- 17m 37s) (1900 2%) 3.8872\n",
            "0m 28s (- 17m 26s) (2000 2%) 3.8885\n",
            "0m 30s (- 17m 25s) (2100 2%) 3.8540\n",
            "0m 31s (- 17m 15s) (2200 2%) 3.8250\n",
            "0m 32s (- 17m 12s) (2300 3%) 3.8436\n",
            "0m 33s (- 17m 4s) (2400 3%) 3.8321\n",
            "0m 35s (- 16m 57s) (2500 3%) 3.8710\n",
            "0m 36s (- 16m 51s) (2600 3%) 3.8202\n",
            "0m 37s (- 16m 43s) (2700 3%) 3.8530\n",
            "0m 38s (- 16m 38s) (2800 3%) 3.8634\n",
            "0m 39s (- 16m 32s) (2900 3%) 3.8283\n",
            "0m 41s (- 16m 31s) (3000 4%) 3.8447\n",
            "0m 42s (- 16m 28s) (3100 4%) 3.8390\n",
            "0m 43s (- 16m 22s) (3200 4%) 3.8520\n",
            "0m 45s (- 16m 18s) (3300 4%) 3.8352\n",
            "0m 46s (- 16m 13s) (3400 4%) 3.8639\n",
            "0m 47s (- 16m 7s) (3500 4%) 3.8175\n",
            "0m 48s (- 16m 4s) (3600 4%) 3.8431\n",
            "0m 49s (- 16m 0s) (3700 4%) 3.8322\n",
            "0m 50s (- 15m 55s) (3800 5%) 3.8493\n",
            "0m 52s (- 15m 50s) (3900 5%) 3.8021\n",
            "0m 53s (- 15m 45s) (4000 5%) 3.8145\n",
            "0m 54s (- 15m 42s) (4100 5%) 3.8203\n",
            "0m 55s (- 15m 40s) (4200 5%) 3.8187\n",
            "0m 56s (- 15m 36s) (4300 5%) 3.8096\n",
            "0m 58s (- 15m 33s) (4400 5%) 3.8128\n",
            "0m 59s (- 15m 30s) (4500 6%) 3.8071\n",
            "1m 0s (- 15m 27s) (4600 6%) 3.8005\n",
            "1m 1s (- 15m 23s) (4700 6%) 3.7864\n",
            "1m 2s (- 15m 19s) (4800 6%) 3.7956\n",
            "1m 4s (- 15m 15s) (4900 6%) 3.8106\n",
            "1m 5s (- 15m 13s) (5000 6%) 3.7995\n",
            "1m 6s (- 15m 11s) (5100 6%) 3.7855\n",
            "1m 7s (- 15m 9s) (5200 6%) 3.7838\n",
            "1m 9s (- 15m 7s) (5300 7%) 3.7859\n",
            "1m 10s (- 15m 5s) (5400 7%) 3.7805\n",
            "1m 11s (- 15m 2s) (5500 7%) 3.8008\n",
            "1m 12s (- 15m 0s) (5600 7%) 3.7336\n",
            "1m 13s (- 14m 58s) (5700 7%) 3.7465\n",
            "1m 15s (- 14m 57s) (5800 7%) 3.7211\n",
            "1m 16s (- 14m 56s) (5900 7%) 3.7448\n",
            "1m 17s (- 14m 54s) (6000 8%) 3.7300\n",
            "1m 19s (- 14m 54s) (6100 8%) 3.7424\n",
            "1m 20s (- 14m 52s) (6200 8%) 3.7464\n",
            "1m 21s (- 14m 50s) (6300 8%) 3.7169\n",
            "1m 22s (- 14m 48s) (6400 8%) 3.7024\n",
            "1m 24s (- 14m 45s) (6500 8%) 3.7065\n",
            "1m 25s (- 14m 43s) (6600 8%) 3.7188\n",
            "1m 26s (- 14m 42s) (6700 8%) 3.6843\n",
            "1m 27s (- 14m 40s) (6800 9%) 3.6379\n",
            "1m 29s (- 14m 40s) (6900 9%) 3.6593\n",
            "1m 30s (- 14m 39s) (7000 9%) 3.6476\n",
            "1m 31s (- 14m 39s) (7100 9%) 3.6557\n",
            "1m 33s (- 14m 39s) (7200 9%) 3.6674\n",
            "1m 34s (- 14m 37s) (7300 9%) 3.6549\n",
            "1m 35s (- 14m 34s) (7400 9%) 3.6405\n",
            "1m 37s (- 14m 33s) (7500 10%) 3.6545\n",
            "1m 38s (- 14m 31s) (7600 10%) 3.5871\n",
            "1m 39s (- 14m 30s) (7700 10%) 3.6160\n",
            "1m 40s (- 14m 29s) (7800 10%) 3.5745\n",
            "1m 42s (- 14m 29s) (7900 10%) 3.5781\n",
            "1m 43s (- 14m 27s) (8000 10%) 3.4779\n",
            "1m 44s (- 14m 26s) (8100 10%) 3.5578\n",
            "1m 46s (- 14m 25s) (8200 10%) 3.5189\n",
            "1m 47s (- 14m 24s) (8300 11%) 3.5643\n",
            "1m 48s (- 14m 23s) (8400 11%) 3.4269\n",
            "1m 50s (- 14m 22s) (8500 11%) 3.5042\n",
            "1m 51s (- 14m 22s) (8600 11%) 3.5249\n",
            "1m 53s (- 14m 21s) (8700 11%) 3.4723\n",
            "1m 54s (- 14m 20s) (8800 11%) 3.4520\n",
            "1m 55s (- 14m 20s) (8900 11%) 3.5115\n",
            "1m 57s (- 14m 19s) (9000 12%) 3.4203\n",
            "1m 58s (- 14m 18s) (9100 12%) 3.3589\n",
            "1m 59s (- 14m 17s) (9200 12%) 3.4210\n",
            "2m 1s (- 14m 16s) (9300 12%) 3.3991\n",
            "2m 2s (- 14m 15s) (9400 12%) 3.3805\n",
            "2m 4s (- 14m 14s) (9500 12%) 3.3644\n",
            "2m 5s (- 14m 13s) (9600 12%) 3.3984\n",
            "2m 6s (- 14m 12s) (9700 12%) 3.4092\n",
            "2m 7s (- 14m 11s) (9800 13%) 3.3896\n",
            "2m 9s (- 14m 10s) (9900 13%) 3.2980\n",
            "2m 10s (- 14m 9s) (10000 13%) 3.1685\n",
            "2m 11s (- 14m 8s) (10100 13%) 3.2228\n",
            "2m 13s (- 14m 7s) (10200 13%) 3.3321\n",
            "2m 14s (- 14m 5s) (10300 13%) 3.2304\n",
            "2m 15s (- 14m 4s) (10400 13%) 3.2284\n",
            "2m 17s (- 14m 3s) (10500 14%) 3.2475\n",
            "2m 18s (- 14m 4s) (10600 14%) 3.1645\n",
            "2m 20s (- 14m 3s) (10700 14%) 3.2912\n",
            "2m 21s (- 14m 2s) (10800 14%) 3.1807\n",
            "2m 23s (- 14m 1s) (10900 14%) 3.2225\n",
            "2m 24s (- 14m 0s) (11000 14%) 3.1865\n",
            "2m 25s (- 13m 59s) (11100 14%) 3.1299\n",
            "2m 27s (- 13m 58s) (11200 14%) 3.1531\n",
            "2m 28s (- 13m 56s) (11300 15%) 3.0932\n",
            "2m 30s (- 13m 57s) (11400 15%) 3.1013\n",
            "2m 31s (- 13m 56s) (11500 15%) 3.0764\n",
            "2m 33s (- 13m 56s) (11600 15%) 3.0234\n",
            "2m 34s (- 13m 55s) (11700 15%) 3.0628\n",
            "2m 35s (- 13m 54s) (11800 15%) 3.0064\n",
            "2m 37s (- 13m 53s) (11900 15%) 2.9926\n",
            "2m 38s (- 13m 52s) (12000 16%) 3.0374\n",
            "2m 39s (- 13m 51s) (12100 16%) 2.9524\n",
            "2m 41s (- 13m 51s) (12200 16%) 2.9312\n",
            "2m 42s (- 13m 50s) (12300 16%) 2.9305\n",
            "2m 44s (- 13m 49s) (12400 16%) 2.8664\n",
            "2m 45s (- 13m 47s) (12500 16%) 2.9104\n",
            "2m 46s (- 13m 46s) (12600 16%) 2.9974\n",
            "2m 48s (- 13m 45s) (12700 16%) 2.8632\n",
            "2m 49s (- 13m 44s) (12800 17%) 2.9681\n",
            "2m 50s (- 13m 43s) (12900 17%) 2.9009\n",
            "2m 52s (- 13m 42s) (13000 17%) 2.7862\n",
            "2m 53s (- 13m 40s) (13100 17%) 2.7754\n",
            "2m 55s (- 13m 40s) (13200 17%) 2.7999\n",
            "2m 56s (- 13m 38s) (13300 17%) 2.7355\n",
            "2m 57s (- 13m 37s) (13400 17%) 2.7510\n",
            "2m 59s (- 13m 36s) (13500 18%) 2.7392\n",
            "3m 0s (- 13m 34s) (13600 18%) 2.6747\n",
            "3m 1s (- 13m 33s) (13700 18%) 2.7392\n",
            "3m 3s (- 13m 32s) (13800 18%) 2.7189\n",
            "3m 4s (- 13m 31s) (13900 18%) 2.6430\n",
            "3m 5s (- 13m 29s) (14000 18%) 2.5848\n",
            "3m 7s (- 13m 29s) (14100 18%) 2.7645\n",
            "3m 8s (- 13m 27s) (14200 18%) 2.6379\n",
            "3m 10s (- 13m 26s) (14300 19%) 2.6294\n",
            "3m 11s (- 13m 25s) (14400 19%) 2.6184\n",
            "3m 12s (- 13m 24s) (14500 19%) 2.7102\n",
            "3m 14s (- 13m 23s) (14600 19%) 2.5934\n",
            "3m 15s (- 13m 22s) (14700 19%) 2.5192\n",
            "3m 16s (- 13m 21s) (14800 19%) 2.4366\n",
            "3m 18s (- 13m 20s) (14900 19%) 2.6168\n",
            "3m 20s (- 13m 20s) (15000 20%) 2.4788\n",
            "3m 21s (- 13m 18s) (15100 20%) 2.4939\n",
            "3m 22s (- 13m 17s) (15200 20%) 2.3832\n",
            "3m 24s (- 13m 16s) (15300 20%) 2.5323\n",
            "3m 25s (- 13m 15s) (15400 20%) 2.3139\n",
            "3m 26s (- 13m 13s) (15500 20%) 2.3953\n",
            "3m 28s (- 13m 12s) (15600 20%) 2.4825\n",
            "3m 29s (- 13m 12s) (15700 20%) 2.3893\n",
            "3m 31s (- 13m 11s) (15800 21%) 2.3791\n",
            "3m 32s (- 13m 11s) (15900 21%) 2.3328\n",
            "3m 34s (- 13m 10s) (16000 21%) 2.3030\n",
            "3m 35s (- 13m 8s) (16100 21%) 2.2383\n",
            "3m 37s (- 13m 7s) (16200 21%) 2.1432\n",
            "3m 38s (- 13m 6s) (16300 21%) 2.2829\n",
            "3m 39s (- 13m 4s) (16400 21%) 2.3294\n",
            "3m 41s (- 13m 4s) (16500 22%) 2.3122\n",
            "3m 42s (- 13m 4s) (16600 22%) 2.1797\n",
            "3m 44s (- 13m 2s) (16700 22%) 2.0595\n",
            "3m 45s (- 13m 1s) (16800 22%) 2.2611\n",
            "3m 47s (- 13m 0s) (16900 22%) 2.1419\n",
            "3m 48s (- 12m 59s) (17000 22%) 2.2260\n",
            "3m 50s (- 12m 58s) (17100 22%) 2.1625\n",
            "3m 51s (- 12m 57s) (17200 22%) 2.1409\n",
            "3m 52s (- 12m 55s) (17300 23%) 2.0695\n",
            "3m 53s (- 12m 54s) (17400 23%) 2.0981\n",
            "3m 55s (- 12m 53s) (17500 23%) 1.9017\n",
            "3m 56s (- 12m 52s) (17600 23%) 2.1206\n",
            "3m 58s (- 12m 51s) (17700 23%) 2.2103\n",
            "3m 59s (- 12m 49s) (17800 23%) 1.9236\n",
            "4m 0s (- 12m 48s) (17900 23%) 2.0539\n",
            "4m 2s (- 12m 46s) (18000 24%) 1.7484\n",
            "4m 3s (- 12m 45s) (18100 24%) 1.8795\n",
            "4m 4s (- 12m 44s) (18200 24%) 2.0768\n",
            "4m 6s (- 12m 43s) (18300 24%) 1.9673\n",
            "4m 7s (- 12m 41s) (18400 24%) 1.8930\n",
            "4m 9s (- 12m 40s) (18500 24%) 1.9125\n",
            "4m 10s (- 12m 39s) (18600 24%) 1.8911\n",
            "4m 11s (- 12m 38s) (18700 24%) 2.0056\n",
            "4m 13s (- 12m 36s) (18800 25%) 1.9283\n",
            "4m 14s (- 12m 35s) (18900 25%) 1.9002\n",
            "4m 15s (- 12m 34s) (19000 25%) 1.8011\n",
            "4m 17s (- 12m 32s) (19100 25%) 1.6928\n",
            "4m 18s (- 12m 32s) (19200 25%) 1.8879\n",
            "4m 20s (- 12m 30s) (19300 25%) 1.6939\n",
            "4m 21s (- 12m 29s) (19400 25%) 1.7946\n",
            "4m 22s (- 12m 28s) (19500 26%) 1.6975\n",
            "4m 24s (- 12m 27s) (19600 26%) 1.6819\n",
            "4m 25s (- 12m 25s) (19700 26%) 1.7930\n",
            "4m 27s (- 12m 24s) (19800 26%) 1.6940\n",
            "4m 28s (- 12m 23s) (19900 26%) 1.6461\n",
            "4m 30s (- 12m 22s) (20000 26%) 1.6271\n",
            "4m 31s (- 12m 21s) (20100 26%) 1.5747\n",
            "4m 33s (- 12m 21s) (20200 26%) 1.7377\n",
            "4m 34s (- 12m 19s) (20300 27%) 1.6409\n",
            "4m 35s (- 12m 18s) (20400 27%) 1.7657\n",
            "4m 37s (- 12m 16s) (20500 27%) 1.7390\n",
            "4m 38s (- 12m 15s) (20600 27%) 1.4742\n",
            "4m 39s (- 12m 14s) (20700 27%) 1.5965\n",
            "4m 41s (- 12m 13s) (20800 27%) 1.7336\n",
            "4m 42s (- 12m 12s) (20900 27%) 1.4128\n",
            "4m 44s (- 12m 10s) (21000 28%) 1.5411\n",
            "4m 45s (- 12m 9s) (21100 28%) 1.6444\n",
            "4m 46s (- 12m 7s) (21200 28%) 1.5002\n",
            "4m 48s (- 12m 6s) (21300 28%) 1.4116\n",
            "4m 49s (- 12m 5s) (21400 28%) 1.3371\n",
            "4m 50s (- 12m 3s) (21500 28%) 1.3972\n",
            "4m 52s (- 12m 1s) (21600 28%) 1.4187\n",
            "4m 53s (- 12m 0s) (21700 28%) 1.5739\n",
            "4m 54s (- 11m 59s) (21800 29%) 1.2907\n",
            "4m 56s (- 11m 57s) (21900 29%) 1.2160\n",
            "4m 57s (- 11m 56s) (22000 29%) 1.2566\n",
            "4m 58s (- 11m 54s) (22100 29%) 1.5210\n",
            "4m 59s (- 11m 53s) (22200 29%) 1.3486\n",
            "5m 1s (- 11m 52s) (22300 29%) 1.4103\n",
            "5m 2s (- 11m 50s) (22400 29%) 1.3934\n",
            "5m 3s (- 11m 49s) (22500 30%) 1.3844\n",
            "5m 5s (- 11m 47s) (22600 30%) 1.3575\n",
            "5m 6s (- 11m 45s) (22700 30%) 1.3222\n",
            "5m 7s (- 11m 44s) (22800 30%) 1.4486\n",
            "5m 8s (- 11m 42s) (22900 30%) 1.2524\n",
            "5m 10s (- 11m 41s) (23000 30%) 1.3863\n",
            "5m 11s (- 11m 40s) (23100 30%) 1.2862\n",
            "5m 12s (- 11m 38s) (23200 30%) 1.2557\n",
            "5m 14s (- 11m 37s) (23300 31%) 1.2606\n",
            "5m 15s (- 11m 36s) (23400 31%) 1.2579\n",
            "5m 16s (- 11m 34s) (23500 31%) 1.0440\n",
            "5m 18s (- 11m 33s) (23600 31%) 1.1941\n",
            "5m 19s (- 11m 32s) (23700 31%) 1.0971\n",
            "5m 21s (- 11m 31s) (23800 31%) 1.1297\n",
            "5m 22s (- 11m 29s) (23900 31%) 1.3726\n",
            "5m 23s (- 11m 28s) (24000 32%) 1.1657\n",
            "5m 25s (- 11m 26s) (24100 32%) 1.2607\n",
            "5m 26s (- 11m 25s) (24200 32%) 1.1276\n",
            "5m 27s (- 11m 24s) (24300 32%) 1.1805\n",
            "5m 29s (- 11m 22s) (24400 32%) 1.1256\n",
            "5m 30s (- 11m 21s) (24500 32%) 1.1052\n",
            "5m 32s (- 11m 20s) (24600 32%) 1.1314\n",
            "5m 33s (- 11m 19s) (24700 32%) 1.2316\n",
            "5m 35s (- 11m 18s) (24800 33%) 1.2349\n",
            "5m 36s (- 11m 16s) (24900 33%) 1.0619\n",
            "5m 37s (- 11m 15s) (25000 33%) 1.0794\n",
            "5m 38s (- 11m 13s) (25100 33%) 1.1268\n",
            "5m 40s (- 11m 12s) (25200 33%) 1.1382\n",
            "5m 41s (- 11m 11s) (25300 33%) 1.0129\n",
            "5m 42s (- 11m 9s) (25400 33%) 1.0035\n",
            "5m 44s (- 11m 8s) (25500 34%) 1.0312\n",
            "5m 45s (- 11m 6s) (25600 34%) 1.0885\n",
            "5m 46s (- 11m 5s) (25700 34%) 0.9264\n",
            "5m 48s (- 11m 3s) (25800 34%) 0.9709\n",
            "5m 49s (- 11m 2s) (25900 34%) 0.8177\n",
            "5m 50s (- 11m 0s) (26000 34%) 1.0585\n",
            "5m 52s (- 10m 59s) (26100 34%) 1.0773\n",
            "5m 53s (- 10m 58s) (26200 34%) 0.8883\n",
            "5m 54s (- 10m 56s) (26300 35%) 1.0329\n",
            "5m 55s (- 10m 55s) (26400 35%) 0.9086\n",
            "5m 57s (- 10m 53s) (26500 35%) 0.9417\n",
            "5m 58s (- 10m 52s) (26600 35%) 0.9021\n",
            "5m 59s (- 10m 50s) (26700 35%) 0.9211\n",
            "6m 1s (- 10m 49s) (26800 35%) 1.0004\n",
            "6m 2s (- 10m 47s) (26900 35%) 0.9291\n",
            "6m 3s (- 10m 46s) (27000 36%) 0.9491\n",
            "6m 4s (- 10m 44s) (27100 36%) 0.9067\n",
            "6m 6s (- 10m 43s) (27200 36%) 1.0100\n",
            "6m 7s (- 10m 41s) (27300 36%) 0.9987\n",
            "6m 8s (- 10m 40s) (27400 36%) 0.8170\n",
            "6m 9s (- 10m 38s) (27500 36%) 0.8004\n",
            "6m 11s (- 10m 37s) (27600 36%) 0.8064\n",
            "6m 12s (- 10m 35s) (27700 36%) 0.8651\n",
            "6m 13s (- 10m 34s) (27800 37%) 0.7992\n",
            "6m 14s (- 10m 32s) (27900 37%) 0.9838\n",
            "6m 16s (- 10m 31s) (28000 37%) 0.8201\n",
            "6m 17s (- 10m 30s) (28100 37%) 0.8751\n",
            "6m 19s (- 10m 29s) (28200 37%) 0.9089\n",
            "6m 20s (- 10m 27s) (28300 37%) 0.8172\n",
            "6m 21s (- 10m 26s) (28400 37%) 1.0063\n",
            "6m 22s (- 10m 24s) (28500 38%) 0.8943\n",
            "6m 24s (- 10m 23s) (28600 38%) 0.7305\n",
            "6m 25s (- 10m 21s) (28700 38%) 0.8461\n",
            "6m 26s (- 10m 20s) (28800 38%) 0.7520\n",
            "6m 27s (- 10m 18s) (28900 38%) 0.8252\n",
            "6m 29s (- 10m 17s) (29000 38%) 0.7767\n",
            "6m 30s (- 10m 16s) (29100 38%) 0.8054\n",
            "6m 32s (- 10m 15s) (29200 38%) 0.8097\n",
            "6m 33s (- 10m 13s) (29300 39%) 0.7555\n",
            "6m 34s (- 10m 12s) (29400 39%) 0.7108\n",
            "6m 36s (- 10m 10s) (29500 39%) 0.8416\n",
            "6m 37s (- 10m 9s) (29600 39%) 0.6987\n",
            "6m 38s (- 10m 8s) (29700 39%) 0.6727\n",
            "6m 40s (- 10m 6s) (29800 39%) 0.7980\n",
            "6m 41s (- 10m 5s) (29900 39%) 0.7277\n",
            "6m 42s (- 10m 4s) (30000 40%) 0.8758\n",
            "6m 44s (- 10m 2s) (30100 40%) 0.6493\n",
            "6m 45s (- 10m 1s) (30200 40%) 0.7793\n",
            "6m 46s (- 9m 59s) (30300 40%) 0.6078\n",
            "6m 47s (- 9m 58s) (30400 40%) 0.6434\n",
            "6m 49s (- 9m 56s) (30500 40%) 0.6207\n",
            "6m 50s (- 9m 55s) (30600 40%) 0.6557\n",
            "6m 51s (- 9m 54s) (30700 40%) 0.7059\n",
            "6m 53s (- 9m 52s) (30800 41%) 0.6415\n",
            "6m 54s (- 9m 51s) (30900 41%) 0.6022\n",
            "6m 55s (- 9m 49s) (31000 41%) 0.6655\n",
            "6m 56s (- 9m 48s) (31100 41%) 0.6423\n",
            "6m 58s (- 9m 46s) (31200 41%) 0.7017\n",
            "6m 59s (- 9m 45s) (31300 41%) 0.6234\n",
            "7m 0s (- 9m 44s) (31400 41%) 0.7272\n",
            "7m 1s (- 9m 42s) (31500 42%) 0.6363\n",
            "7m 3s (- 9m 41s) (31600 42%) 0.5346\n",
            "7m 4s (- 9m 39s) (31700 42%) 0.7044\n",
            "7m 5s (- 9m 38s) (31800 42%) 0.6498\n",
            "7m 7s (- 9m 36s) (31900 42%) 0.7143\n",
            "7m 8s (- 9m 35s) (32000 42%) 0.6186\n",
            "7m 9s (- 9m 34s) (32100 42%) 0.5702\n",
            "7m 11s (- 9m 32s) (32200 42%) 0.5918\n",
            "7m 12s (- 9m 31s) (32300 43%) 0.7018\n",
            "7m 13s (- 9m 30s) (32400 43%) 0.7019\n",
            "7m 14s (- 9m 28s) (32500 43%) 0.5623\n",
            "7m 16s (- 9m 27s) (32600 43%) 0.6835\n",
            "7m 17s (- 9m 26s) (32700 43%) 0.6867\n",
            "7m 19s (- 9m 24s) (32800 43%) 0.6049\n",
            "7m 20s (- 9m 23s) (32900 43%) 0.6252\n",
            "7m 21s (- 9m 22s) (33000 44%) 0.6917\n",
            "7m 22s (- 9m 20s) (33100 44%) 0.5009\n",
            "7m 24s (- 9m 19s) (33200 44%) 0.6360\n",
            "7m 25s (- 9m 17s) (33300 44%) 0.6476\n",
            "7m 26s (- 9m 16s) (33400 44%) 0.6896\n",
            "7m 28s (- 9m 15s) (33500 44%) 0.6231\n",
            "7m 29s (- 9m 14s) (33600 44%) 0.5831\n",
            "7m 30s (- 9m 12s) (33700 44%) 0.5206\n",
            "7m 32s (- 9m 11s) (33800 45%) 0.5865\n",
            "7m 33s (- 9m 10s) (33900 45%) 0.5524\n",
            "7m 34s (- 9m 8s) (34000 45%) 0.4553\n",
            "7m 36s (- 9m 7s) (34100 45%) 0.5576\n",
            "7m 37s (- 9m 5s) (34200 45%) 0.5684\n",
            "7m 38s (- 9m 4s) (34300 45%) 0.6380\n",
            "7m 40s (- 9m 3s) (34400 45%) 0.5842\n",
            "7m 41s (- 9m 1s) (34500 46%) 0.4658\n",
            "7m 43s (- 9m 0s) (34600 46%) 0.4739\n",
            "7m 44s (- 8m 59s) (34700 46%) 0.5848\n",
            "7m 45s (- 8m 57s) (34800 46%) 0.4759\n",
            "7m 46s (- 8m 56s) (34900 46%) 0.4883\n",
            "7m 48s (- 8m 54s) (35000 46%) 0.4204\n",
            "7m 49s (- 8m 53s) (35100 46%) 0.5808\n",
            "7m 50s (- 8m 52s) (35200 46%) 0.5831\n",
            "7m 51s (- 8m 50s) (35300 47%) 0.5034\n",
            "7m 53s (- 8m 49s) (35400 47%) 0.4157\n",
            "7m 54s (- 8m 47s) (35500 47%) 0.5308\n",
            "7m 55s (- 8m 46s) (35600 47%) 0.5743\n",
            "7m 56s (- 8m 45s) (35700 47%) 0.4161\n",
            "7m 58s (- 8m 43s) (35800 47%) 0.5059\n",
            "7m 59s (- 8m 42s) (35900 47%) 0.5900\n",
            "8m 0s (- 8m 40s) (36000 48%) 0.4079\n",
            "8m 1s (- 8m 39s) (36100 48%) 0.4286\n",
            "8m 3s (- 8m 37s) (36200 48%) 0.4593\n",
            "8m 4s (- 8m 36s) (36300 48%) 0.4526\n",
            "8m 5s (- 8m 34s) (36400 48%) 0.4530\n",
            "8m 6s (- 8m 33s) (36500 48%) 0.4643\n",
            "8m 8s (- 8m 32s) (36600 48%) 0.4824\n",
            "8m 9s (- 8m 30s) (36700 48%) 0.5564\n",
            "8m 10s (- 8m 29s) (36800 49%) 0.5402\n",
            "8m 11s (- 8m 27s) (36900 49%) 0.4412\n",
            "8m 13s (- 8m 26s) (37000 49%) 0.3928\n",
            "8m 14s (- 8m 25s) (37100 49%) 0.4040\n",
            "8m 15s (- 8m 23s) (37200 49%) 0.4086\n",
            "8m 16s (- 8m 22s) (37300 49%) 0.4356\n",
            "8m 18s (- 8m 21s) (37400 49%) 0.5586\n",
            "8m 19s (- 8m 19s) (37500 50%) 0.3658\n",
            "8m 21s (- 8m 18s) (37600 50%) 0.4162\n",
            "8m 22s (- 8m 17s) (37700 50%) 0.4844\n",
            "8m 23s (- 8m 15s) (37800 50%) 0.4624\n",
            "8m 24s (- 8m 14s) (37900 50%) 0.4493\n",
            "8m 26s (- 8m 12s) (38000 50%) 0.4853\n",
            "8m 27s (- 8m 11s) (38100 50%) 0.5214\n",
            "8m 28s (- 8m 9s) (38200 50%) 0.3688\n",
            "8m 30s (- 8m 8s) (38300 51%) 0.4798\n",
            "8m 31s (- 8m 7s) (38400 51%) 0.3884\n",
            "8m 33s (- 8m 6s) (38500 51%) 0.4331\n",
            "8m 34s (- 8m 4s) (38600 51%) 0.4566\n",
            "8m 35s (- 8m 3s) (38700 51%) 0.4717\n",
            "8m 36s (- 8m 2s) (38800 51%) 0.3928\n",
            "8m 37s (- 8m 0s) (38900 51%) 0.3465\n",
            "8m 39s (- 7m 59s) (39000 52%) 0.4205\n",
            "8m 40s (- 7m 57s) (39100 52%) 0.3850\n",
            "8m 42s (- 7m 56s) (39200 52%) 0.4924\n",
            "8m 43s (- 7m 55s) (39300 52%) 0.3073\n",
            "8m 44s (- 7m 54s) (39400 52%) 0.3970\n",
            "8m 45s (- 7m 52s) (39500 52%) 0.3899\n",
            "8m 47s (- 7m 51s) (39600 52%) 0.3727\n",
            "8m 48s (- 7m 49s) (39700 52%) 0.4387\n",
            "8m 49s (- 7m 48s) (39800 53%) 0.4775\n",
            "8m 50s (- 7m 47s) (39900 53%) 0.4517\n",
            "8m 52s (- 7m 45s) (40000 53%) 0.4344\n",
            "8m 53s (- 7m 44s) (40100 53%) 0.4543\n",
            "8m 54s (- 7m 43s) (40200 53%) 0.4646\n",
            "8m 56s (- 7m 41s) (40300 53%) 0.3975\n",
            "8m 57s (- 7m 40s) (40400 53%) 0.3800\n",
            "8m 58s (- 7m 38s) (40500 54%) 0.5505\n",
            "9m 0s (- 7m 37s) (40600 54%) 0.3352\n",
            "9m 1s (- 7m 36s) (40700 54%) 0.3926\n",
            "9m 2s (- 7m 34s) (40800 54%) 0.4568\n",
            "9m 3s (- 7m 33s) (40900 54%) 0.3389\n",
            "9m 5s (- 7m 32s) (41000 54%) 0.4614\n",
            "9m 6s (- 7m 30s) (41100 54%) 0.3485\n",
            "9m 7s (- 7m 29s) (41200 54%) 0.4260\n",
            "9m 8s (- 7m 27s) (41300 55%) 0.3604\n",
            "9m 10s (- 7m 26s) (41400 55%) 0.4579\n",
            "9m 11s (- 7m 25s) (41500 55%) 0.4184\n",
            "9m 12s (- 7m 23s) (41600 55%) 0.3715\n",
            "9m 13s (- 7m 22s) (41700 55%) 0.4165\n",
            "9m 15s (- 7m 20s) (41800 55%) 0.4287\n",
            "9m 16s (- 7m 19s) (41900 55%) 0.3973\n",
            "9m 17s (- 7m 18s) (42000 56%) 0.3597\n",
            "9m 19s (- 7m 17s) (42100 56%) 0.3937\n",
            "9m 20s (- 7m 15s) (42200 56%) 0.4084\n",
            "9m 21s (- 7m 14s) (42300 56%) 0.4460\n",
            "9m 23s (- 7m 12s) (42400 56%) 0.4397\n",
            "9m 24s (- 7m 11s) (42500 56%) 0.3896\n",
            "9m 25s (- 7m 10s) (42600 56%) 0.4137\n",
            "9m 26s (- 7m 8s) (42700 56%) 0.2823\n",
            "9m 28s (- 7m 7s) (42800 57%) 0.3790\n",
            "9m 29s (- 7m 6s) (42900 57%) 0.4210\n",
            "9m 30s (- 7m 4s) (43000 57%) 0.4126\n",
            "9m 32s (- 7m 3s) (43100 57%) 0.3230\n",
            "9m 33s (- 7m 2s) (43200 57%) 0.3717\n",
            "9m 34s (- 7m 0s) (43300 57%) 0.3585\n",
            "9m 36s (- 6m 59s) (43400 57%) 0.2803\n",
            "9m 37s (- 6m 58s) (43500 57%) 0.4219\n",
            "9m 38s (- 6m 56s) (43600 58%) 0.3632\n",
            "9m 39s (- 6m 55s) (43700 58%) 0.4816\n",
            "9m 41s (- 6m 54s) (43800 58%) 0.3558\n",
            "9m 42s (- 6m 52s) (43900 58%) 0.4182\n",
            "9m 43s (- 6m 51s) (44000 58%) 0.2873\n",
            "9m 45s (- 6m 50s) (44100 58%) 0.3329\n",
            "9m 46s (- 6m 48s) (44200 58%) 0.4512\n",
            "9m 47s (- 6m 47s) (44300 59%) 0.4405\n",
            "9m 48s (- 6m 45s) (44400 59%) 0.3426\n",
            "9m 50s (- 6m 44s) (44500 59%) 0.4027\n",
            "9m 51s (- 6m 43s) (44600 59%) 0.3702\n",
            "9m 52s (- 6m 41s) (44700 59%) 0.3931\n",
            "9m 53s (- 6m 40s) (44800 59%) 0.3373\n",
            "9m 55s (- 6m 39s) (44900 59%) 0.3810\n",
            "9m 56s (- 6m 37s) (45000 60%) 0.2683\n",
            "9m 57s (- 6m 36s) (45100 60%) 0.2913\n",
            "9m 59s (- 6m 34s) (45200 60%) 0.3746\n",
            "10m 0s (- 6m 33s) (45300 60%) 0.3759\n",
            "10m 1s (- 6m 32s) (45400 60%) 0.3834\n",
            "10m 2s (- 6m 30s) (45500 60%) 0.2798\n",
            "10m 4s (- 6m 29s) (45600 60%) 0.3170\n",
            "10m 5s (- 6m 28s) (45700 60%) 0.4034\n",
            "10m 6s (- 6m 26s) (45800 61%) 0.2334\n",
            "10m 7s (- 6m 25s) (45900 61%) 0.4454\n",
            "10m 9s (- 6m 24s) (46000 61%) 0.4064\n",
            "10m 10s (- 6m 22s) (46100 61%) 0.2776\n",
            "10m 11s (- 6m 21s) (46200 61%) 0.3919\n",
            "10m 12s (- 6m 19s) (46300 61%) 0.3079\n",
            "10m 14s (- 6m 18s) (46400 61%) 0.3427\n",
            "10m 15s (- 6m 17s) (46500 62%) 0.4209\n",
            "10m 16s (- 6m 15s) (46600 62%) 0.3240\n",
            "10m 17s (- 6m 14s) (46700 62%) 0.3384\n",
            "10m 19s (- 6m 13s) (46800 62%) 0.3285\n",
            "10m 20s (- 6m 11s) (46900 62%) 0.2526\n",
            "10m 21s (- 6m 10s) (47000 62%) 0.4655\n",
            "10m 23s (- 6m 9s) (47100 62%) 0.3167\n",
            "10m 24s (- 6m 7s) (47200 62%) 0.3800\n",
            "10m 25s (- 6m 6s) (47300 63%) 0.2934\n",
            "10m 27s (- 6m 5s) (47400 63%) 0.2971\n",
            "10m 28s (- 6m 3s) (47500 63%) 0.3858\n",
            "10m 29s (- 6m 2s) (47600 63%) 0.2787\n",
            "10m 31s (- 6m 1s) (47700 63%) 0.2540\n",
            "10m 32s (- 5m 59s) (47800 63%) 0.4048\n",
            "10m 33s (- 5m 58s) (47900 63%) 0.3556\n",
            "10m 35s (- 5m 57s) (48000 64%) 0.3436\n",
            "10m 36s (- 5m 55s) (48100 64%) 0.2716\n",
            "10m 37s (- 5m 54s) (48200 64%) 0.3399\n",
            "10m 39s (- 5m 53s) (48300 64%) 0.4149\n",
            "10m 40s (- 5m 52s) (48400 64%) 0.3632\n",
            "10m 42s (- 5m 50s) (48500 64%) 0.2302\n",
            "10m 43s (- 5m 49s) (48600 64%) 0.3368\n",
            "10m 44s (- 5m 48s) (48700 64%) 0.3288\n",
            "10m 45s (- 5m 46s) (48800 65%) 0.3112\n",
            "10m 46s (- 5m 45s) (48900 65%) 0.3512\n",
            "10m 48s (- 5m 43s) (49000 65%) 0.3023\n",
            "10m 49s (- 5m 42s) (49100 65%) 0.2398\n",
            "10m 50s (- 5m 41s) (49200 65%) 0.2602\n",
            "10m 52s (- 5m 39s) (49300 65%) 0.2821\n",
            "10m 53s (- 5m 38s) (49400 65%) 0.3446\n",
            "10m 54s (- 5m 37s) (49500 66%) 0.3867\n",
            "10m 56s (- 5m 36s) (49600 66%) 0.3224\n",
            "10m 57s (- 5m 34s) (49700 66%) 0.3301\n",
            "10m 58s (- 5m 33s) (49800 66%) 0.3121\n",
            "10m 59s (- 5m 31s) (49900 66%) 0.2938\n",
            "11m 1s (- 5m 30s) (50000 66%) 0.2928\n",
            "11m 2s (- 5m 29s) (50100 66%) 0.2530\n",
            "11m 3s (- 5m 27s) (50200 66%) 0.2830\n",
            "11m 4s (- 5m 26s) (50300 67%) 0.2844\n",
            "11m 6s (- 5m 25s) (50400 67%) 0.3294\n",
            "11m 7s (- 5m 23s) (50500 67%) 0.2163\n",
            "11m 8s (- 5m 22s) (50600 67%) 0.2385\n",
            "11m 9s (- 5m 21s) (50700 67%) 0.3341\n",
            "11m 11s (- 5m 19s) (50800 67%) 0.2816\n",
            "11m 12s (- 5m 18s) (50900 67%) 0.3325\n",
            "11m 13s (- 5m 17s) (51000 68%) 0.3210\n",
            "11m 15s (- 5m 15s) (51100 68%) 0.3080\n",
            "11m 16s (- 5m 14s) (51200 68%) 0.2698\n",
            "11m 17s (- 5m 13s) (51300 68%) 0.2668\n",
            "11m 19s (- 5m 11s) (51400 68%) 0.2992\n",
            "11m 20s (- 5m 10s) (51500 68%) 0.2463\n",
            "11m 21s (- 5m 9s) (51600 68%) 0.2224\n",
            "11m 22s (- 5m 7s) (51700 68%) 0.2737\n",
            "11m 24s (- 5m 6s) (51800 69%) 0.2506\n",
            "11m 25s (- 5m 5s) (51900 69%) 0.2562\n",
            "11m 26s (- 5m 3s) (52000 69%) 0.3067\n",
            "11m 28s (- 5m 2s) (52100 69%) 0.2622\n",
            "11m 29s (- 5m 1s) (52200 69%) 0.3235\n",
            "11m 30s (- 4m 59s) (52300 69%) 0.2104\n",
            "11m 32s (- 4m 58s) (52400 69%) 0.2478\n",
            "11m 33s (- 4m 57s) (52500 70%) 0.2865\n",
            "11m 35s (- 4m 55s) (52600 70%) 0.2598\n",
            "11m 36s (- 4m 54s) (52700 70%) 0.2778\n",
            "11m 37s (- 4m 53s) (52800 70%) 0.2524\n",
            "11m 38s (- 4m 52s) (52900 70%) 0.2283\n",
            "11m 40s (- 4m 50s) (53000 70%) 0.2648\n",
            "11m 41s (- 4m 49s) (53100 70%) 0.2612\n",
            "11m 42s (- 4m 48s) (53200 70%) 0.2899\n",
            "11m 44s (- 4m 46s) (53300 71%) 0.3203\n",
            "11m 45s (- 4m 45s) (53400 71%) 0.2001\n",
            "11m 46s (- 4m 44s) (53500 71%) 0.2811\n",
            "11m 47s (- 4m 42s) (53600 71%) 0.2205\n",
            "11m 49s (- 4m 41s) (53700 71%) 0.3638\n",
            "11m 50s (- 4m 39s) (53800 71%) 0.2870\n",
            "11m 51s (- 4m 38s) (53900 71%) 0.2561\n",
            "11m 53s (- 4m 37s) (54000 72%) 0.2618\n",
            "11m 54s (- 4m 35s) (54100 72%) 0.3592\n",
            "11m 55s (- 4m 34s) (54200 72%) 0.2544\n",
            "11m 56s (- 4m 33s) (54300 72%) 0.2800\n",
            "11m 58s (- 4m 31s) (54400 72%) 0.2679\n",
            "11m 59s (- 4m 30s) (54500 72%) 0.2393\n",
            "12m 0s (- 4m 29s) (54600 72%) 0.2099\n",
            "12m 1s (- 4m 27s) (54700 72%) 0.2908\n",
            "12m 3s (- 4m 26s) (54800 73%) 0.2543\n",
            "12m 4s (- 4m 25s) (54900 73%) 0.2250\n",
            "12m 5s (- 4m 23s) (55000 73%) 0.2218\n",
            "12m 6s (- 4m 22s) (55100 73%) 0.2562\n",
            "12m 8s (- 4m 21s) (55200 73%) 0.2153\n",
            "12m 9s (- 4m 19s) (55300 73%) 0.1481\n",
            "12m 10s (- 4m 18s) (55400 73%) 0.3614\n",
            "12m 12s (- 4m 17s) (55500 74%) 0.1944\n",
            "12m 13s (- 4m 15s) (55600 74%) 0.2171\n",
            "12m 14s (- 4m 14s) (55700 74%) 0.2239\n",
            "12m 15s (- 4m 13s) (55800 74%) 0.2600\n",
            "12m 17s (- 4m 11s) (55900 74%) 0.2680\n",
            "12m 18s (- 4m 10s) (56000 74%) 0.2769\n",
            "12m 19s (- 4m 9s) (56100 74%) 0.2034\n",
            "12m 21s (- 4m 7s) (56200 74%) 0.2417\n",
            "12m 22s (- 4m 6s) (56300 75%) 0.2269\n",
            "12m 23s (- 4m 5s) (56400 75%) 0.2255\n",
            "12m 24s (- 4m 3s) (56500 75%) 0.2305\n",
            "12m 26s (- 4m 2s) (56600 75%) 0.1901\n",
            "12m 27s (- 4m 1s) (56700 75%) 0.3285\n",
            "12m 28s (- 3m 59s) (56800 75%) 0.2479\n",
            "12m 30s (- 3m 58s) (56900 75%) 0.2453\n",
            "12m 31s (- 3m 57s) (57000 76%) 0.2501\n",
            "12m 32s (- 3m 56s) (57100 76%) 0.2036\n",
            "12m 34s (- 3m 54s) (57200 76%) 0.3107\n",
            "12m 35s (- 3m 53s) (57300 76%) 0.2366\n",
            "12m 36s (- 3m 52s) (57400 76%) 0.2146\n",
            "12m 38s (- 3m 50s) (57500 76%) 0.2322\n",
            "12m 39s (- 3m 49s) (57600 76%) 0.1986\n",
            "12m 40s (- 3m 48s) (57700 76%) 0.1827\n",
            "12m 42s (- 3m 46s) (57800 77%) 0.1953\n",
            "12m 43s (- 3m 45s) (57900 77%) 0.1973\n",
            "12m 44s (- 3m 44s) (58000 77%) 0.2102\n",
            "12m 45s (- 3m 42s) (58100 77%) 0.2151\n",
            "12m 47s (- 3m 41s) (58200 77%) 0.2107\n",
            "12m 48s (- 3m 40s) (58300 77%) 0.2113\n",
            "12m 49s (- 3m 38s) (58400 77%) 0.2444\n",
            "12m 50s (- 3m 37s) (58500 78%) 0.2300\n",
            "12m 52s (- 3m 36s) (58600 78%) 0.2617\n",
            "12m 53s (- 3m 34s) (58700 78%) 0.2099\n",
            "12m 54s (- 3m 33s) (58800 78%) 0.2231\n",
            "12m 56s (- 3m 32s) (58900 78%) 0.2313\n",
            "12m 57s (- 3m 30s) (59000 78%) 0.2442\n",
            "12m 58s (- 3m 29s) (59100 78%) 0.2347\n",
            "12m 59s (- 3m 28s) (59200 78%) 0.2157\n",
            "13m 1s (- 3m 26s) (59300 79%) 0.2657\n",
            "13m 2s (- 3m 25s) (59400 79%) 0.2045\n",
            "13m 3s (- 3m 24s) (59500 79%) 0.2318\n",
            "13m 4s (- 3m 22s) (59600 79%) 0.2440\n",
            "13m 5s (- 3m 21s) (59700 79%) 0.1841\n",
            "13m 7s (- 3m 20s) (59800 79%) 0.2068\n",
            "13m 8s (- 3m 18s) (59900 79%) 0.2184\n",
            "13m 9s (- 3m 17s) (60000 80%) 0.1975\n",
            "13m 10s (- 3m 16s) (60100 80%) 0.1942\n",
            "13m 12s (- 3m 14s) (60200 80%) 0.2455\n",
            "13m 13s (- 3m 13s) (60300 80%) 0.1558\n",
            "13m 14s (- 3m 12s) (60400 80%) 0.2227\n",
            "13m 15s (- 3m 10s) (60500 80%) 0.2057\n",
            "13m 17s (- 3m 9s) (60600 80%) 0.2620\n",
            "13m 18s (- 3m 8s) (60700 80%) 0.1500\n",
            "13m 19s (- 3m 6s) (60800 81%) 0.2284\n",
            "13m 21s (- 3m 5s) (60900 81%) 0.2623\n",
            "13m 22s (- 3m 4s) (61000 81%) 0.1938\n",
            "13m 23s (- 3m 2s) (61100 81%) 0.1641\n",
            "13m 24s (- 3m 1s) (61200 81%) 0.2232\n",
            "13m 26s (- 3m 0s) (61300 81%) 0.1670\n",
            "13m 27s (- 2m 58s) (61400 81%) 0.1602\n",
            "13m 28s (- 2m 57s) (61500 82%) 0.2105\n",
            "13m 30s (- 2m 56s) (61600 82%) 0.2307\n",
            "13m 31s (- 2m 54s) (61700 82%) 0.1947\n",
            "13m 32s (- 2m 53s) (61800 82%) 0.2108\n",
            "13m 34s (- 2m 52s) (61900 82%) 0.1745\n",
            "13m 35s (- 2m 50s) (62000 82%) 0.2022\n",
            "13m 36s (- 2m 49s) (62100 82%) 0.2037\n",
            "13m 37s (- 2m 48s) (62200 82%) 0.1983\n",
            "13m 39s (- 2m 46s) (62300 83%) 0.2098\n",
            "13m 40s (- 2m 45s) (62400 83%) 0.1981\n",
            "13m 41s (- 2m 44s) (62500 83%) 0.2280\n",
            "13m 43s (- 2m 43s) (62600 83%) 0.1972\n",
            "13m 44s (- 2m 41s) (62700 83%) 0.2336\n",
            "13m 45s (- 2m 40s) (62800 83%) 0.2197\n",
            "13m 46s (- 2m 39s) (62900 83%) 0.1314\n",
            "13m 48s (- 2m 37s) (63000 84%) 0.1467\n",
            "13m 49s (- 2m 36s) (63100 84%) 0.2026\n",
            "13m 50s (- 2m 35s) (63200 84%) 0.2146\n",
            "13m 51s (- 2m 33s) (63300 84%) 0.1755\n",
            "13m 53s (- 2m 32s) (63400 84%) 0.1779\n",
            "13m 54s (- 2m 31s) (63500 84%) 0.1637\n",
            "13m 55s (- 2m 29s) (63600 84%) 0.2799\n",
            "13m 56s (- 2m 28s) (63700 84%) 0.2101\n",
            "13m 58s (- 2m 27s) (63800 85%) 0.1814\n",
            "13m 59s (- 2m 25s) (63900 85%) 0.1600\n",
            "14m 0s (- 2m 24s) (64000 85%) 0.1536\n",
            "14m 2s (- 2m 23s) (64100 85%) 0.1822\n",
            "14m 3s (- 2m 21s) (64200 85%) 0.2052\n",
            "14m 4s (- 2m 20s) (64300 85%) 0.1526\n",
            "14m 6s (- 2m 19s) (64400 85%) 0.1253\n",
            "14m 7s (- 2m 17s) (64500 86%) 0.1728\n",
            "14m 8s (- 2m 16s) (64600 86%) 0.1341\n",
            "14m 9s (- 2m 15s) (64700 86%) 0.1603\n",
            "14m 11s (- 2m 13s) (64800 86%) 0.2332\n",
            "14m 12s (- 2m 12s) (64900 86%) 0.1847\n",
            "14m 13s (- 2m 11s) (65000 86%) 0.1722\n",
            "14m 14s (- 2m 10s) (65100 86%) 0.1416\n",
            "14m 16s (- 2m 8s) (65200 86%) 0.1782\n",
            "14m 17s (- 2m 7s) (65300 87%) 0.1977\n",
            "14m 18s (- 2m 6s) (65400 87%) 0.2478\n",
            "14m 20s (- 2m 4s) (65500 87%) 0.1783\n",
            "14m 21s (- 2m 3s) (65600 87%) 0.1745\n",
            "14m 22s (- 2m 2s) (65700 87%) 0.2059\n",
            "14m 23s (- 2m 0s) (65800 87%) 0.2772\n",
            "14m 25s (- 1m 59s) (65900 87%) 0.1994\n",
            "14m 26s (- 1m 58s) (66000 88%) 0.1610\n",
            "14m 27s (- 1m 56s) (66100 88%) 0.2042\n",
            "14m 29s (- 1m 55s) (66200 88%) 0.1786\n",
            "14m 30s (- 1m 54s) (66300 88%) 0.2023\n",
            "14m 31s (- 1m 52s) (66400 88%) 0.1951\n",
            "14m 33s (- 1m 51s) (66500 88%) 0.1740\n",
            "14m 34s (- 1m 50s) (66600 88%) 0.1432\n",
            "14m 35s (- 1m 48s) (66700 88%) 0.2165\n",
            "14m 36s (- 1m 47s) (66800 89%) 0.2105\n",
            "14m 38s (- 1m 46s) (66900 89%) 0.1705\n",
            "14m 39s (- 1m 45s) (67000 89%) 0.1494\n",
            "14m 40s (- 1m 43s) (67100 89%) 0.1812\n",
            "14m 42s (- 1m 42s) (67200 89%) 0.1779\n",
            "14m 43s (- 1m 41s) (67300 89%) 0.1915\n",
            "14m 44s (- 1m 39s) (67400 89%) 0.2071\n",
            "14m 45s (- 1m 38s) (67500 90%) 0.2000\n",
            "14m 47s (- 1m 37s) (67600 90%) 0.1815\n",
            "14m 48s (- 1m 35s) (67700 90%) 0.1663\n",
            "14m 49s (- 1m 34s) (67800 90%) 0.1991\n",
            "14m 50s (- 1m 33s) (67900 90%) 0.2098\n",
            "14m 52s (- 1m 31s) (68000 90%) 0.1727\n",
            "14m 53s (- 1m 30s) (68100 90%) 0.1726\n",
            "14m 54s (- 1m 29s) (68200 90%) 0.1775\n",
            "14m 55s (- 1m 27s) (68300 91%) 0.1366\n",
            "14m 57s (- 1m 26s) (68400 91%) 0.2093\n",
            "14m 58s (- 1m 25s) (68500 91%) 0.2078\n",
            "14m 59s (- 1m 23s) (68600 91%) 0.1339\n",
            "15m 0s (- 1m 22s) (68700 91%) 0.1343\n",
            "15m 2s (- 1m 21s) (68800 91%) 0.1376\n",
            "15m 3s (- 1m 19s) (68900 91%) 0.1234\n",
            "15m 4s (- 1m 18s) (69000 92%) 0.1567\n",
            "15m 5s (- 1m 17s) (69100 92%) 0.2177\n",
            "15m 7s (- 1m 16s) (69200 92%) 0.1636\n",
            "15m 8s (- 1m 14s) (69300 92%) 0.1236\n",
            "15m 9s (- 1m 13s) (69400 92%) 0.1923\n",
            "15m 10s (- 1m 12s) (69500 92%) 0.1555\n",
            "15m 12s (- 1m 10s) (69600 92%) 0.0896\n",
            "15m 13s (- 1m 9s) (69700 92%) 0.2017\n",
            "15m 14s (- 1m 8s) (69800 93%) 0.1553\n",
            "15m 15s (- 1m 6s) (69900 93%) 0.1839\n",
            "15m 17s (- 1m 5s) (70000 93%) 0.1299\n",
            "15m 18s (- 1m 4s) (70100 93%) 0.1652\n",
            "15m 19s (- 1m 2s) (70200 93%) 0.1500\n",
            "15m 21s (- 1m 1s) (70300 93%) 0.1860\n",
            "15m 22s (- 1m 0s) (70400 93%) 0.1718\n",
            "15m 23s (- 0m 58s) (70500 94%) 0.2161\n",
            "15m 24s (- 0m 57s) (70600 94%) 0.1640\n",
            "15m 26s (- 0m 56s) (70700 94%) 0.1508\n",
            "15m 27s (- 0m 55s) (70800 94%) 0.1127\n",
            "15m 28s (- 0m 53s) (70900 94%) 0.1379\n",
            "15m 30s (- 0m 52s) (71000 94%) 0.1910\n",
            "15m 31s (- 0m 51s) (71100 94%) 0.2017\n",
            "15m 33s (- 0m 49s) (71200 94%) 0.1199\n",
            "15m 34s (- 0m 48s) (71300 95%) 0.1899\n",
            "15m 35s (- 0m 47s) (71400 95%) 0.1460\n",
            "15m 36s (- 0m 45s) (71500 95%) 0.1623\n",
            "15m 37s (- 0m 44s) (71600 95%) 0.0806\n",
            "15m 39s (- 0m 43s) (71700 95%) 0.1656\n",
            "15m 40s (- 0m 41s) (71800 95%) 0.1617\n",
            "15m 41s (- 0m 40s) (71900 95%) 0.1575\n",
            "15m 43s (- 0m 39s) (72000 96%) 0.1482\n",
            "15m 44s (- 0m 37s) (72100 96%) 0.2125\n",
            "15m 45s (- 0m 36s) (72200 96%) 0.1119\n",
            "15m 46s (- 0m 35s) (72300 96%) 0.1155\n",
            "15m 48s (- 0m 34s) (72400 96%) 0.1507\n",
            "15m 49s (- 0m 32s) (72500 96%) 0.1960\n",
            "15m 50s (- 0m 31s) (72600 96%) 0.1127\n",
            "15m 51s (- 0m 30s) (72700 96%) 0.1414\n",
            "15m 53s (- 0m 28s) (72800 97%) 0.1375\n",
            "15m 54s (- 0m 27s) (72900 97%) 0.1819\n",
            "15m 55s (- 0m 26s) (73000 97%) 0.1023\n",
            "15m 57s (- 0m 24s) (73100 97%) 0.1296\n",
            "15m 58s (- 0m 23s) (73200 97%) 0.1357\n",
            "15m 59s (- 0m 22s) (73300 97%) 0.1090\n",
            "16m 0s (- 0m 20s) (73400 97%) 0.1232\n",
            "16m 2s (- 0m 19s) (73500 98%) 0.1138\n",
            "16m 3s (- 0m 18s) (73600 98%) 0.1223\n",
            "16m 4s (- 0m 17s) (73700 98%) 0.1368\n",
            "16m 5s (- 0m 15s) (73800 98%) 0.1776\n",
            "16m 7s (- 0m 14s) (73900 98%) 0.1120\n",
            "16m 8s (- 0m 13s) (74000 98%) 0.1539\n",
            "16m 9s (- 0m 11s) (74100 98%) 0.1743\n",
            "16m 10s (- 0m 10s) (74200 98%) 0.1502\n",
            "16m 12s (- 0m 9s) (74300 99%) 0.1451\n",
            "16m 13s (- 0m 7s) (74400 99%) 0.1922\n",
            "16m 14s (- 0m 6s) (74500 99%) 0.1585\n",
            "16m 16s (- 0m 5s) (74600 99%) 0.2365\n",
            "16m 17s (- 0m 3s) (74700 99%) 0.1775\n",
            "16m 18s (- 0m 2s) (74800 99%) 0.1835\n",
            "16m 19s (- 0m 1s) (74900 99%) 0.1311\n",
            "16m 21s (- 0m 0s) (75000 100%) 0.1345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9u3eQslGxTW",
        "colab_type": "code",
        "outputId": "955f11c2-86b2-489c-a347-89ff2623ff9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> sort a multidimensional array `a` by column with index 1\n",
            "= sorted(a, key=lambda x: x[1])\n",
            "< sorted(a, key=lambda x: x[1]) <EOS>\n",
            "\n",
            "> getting every possible combination of two elements in a list\n",
            "= list(itertools.combinations([1, 2, 3, 4, 5, 6], 2))\n",
            "< list(itertools.combinations([1, 2, 3, 4, 5, 6], 2)) <EOS>\n",
            "\n",
            "> Calling an external command \"echo Hello World\"\n",
            "= return_code = subprocess.call('echo Hello World', shell=True)\n",
            "< print(os.popen('echo Hello World').read()) <EOS>\n",
            "\n",
            "> calculate the sum of the squares of each value in list `l`\n",
            "= sum(map(lambda x: x * x, l))\n",
            "< sum(map(lambda x: x * x, l)) <EOS>\n",
            "\n",
            "> assign value in `group` dynamically to class property `attr`\n",
            "= setattr(self, attr, group)\n",
            "< setattr(self, attr, group) <EOS>\n",
            "\n",
            "> prompt string 'Press Enter to continue...' to the console\n",
            "= input('Press Enter to continue...')\n",
            "< input('Press Enter to continue...') <EOS>\n",
            "\n",
            "> check if a local variable `myVar` exists\n",
            "= ('myVar' in locals())\n",
            "< ('myVar' in globals()) <EOS>\n",
            "\n",
            "> convert a DateTime string back to a DateTime object of format '%Y-%m-%d %H:%M:%S.%f'\n",
            "= datetime.strptime('2010-11-13 10:33:54.227806', '%Y-%m-%d %H:%M:%S.%f')\n",
            "< datetime.strptime('2010-11-13 10:33:54.227806', '%Y-%m-%d %H:%M:%S.%f') <EOS>\n",
            "\n",
            "> remove all duplicate items from a list `lseperatedOrblist`\n",
            "= woduplicates = list(set(lseperatedOrblist))\n",
            "< woduplicates = list(set(lseperatedOrblist)) <EOS>\n",
            "\n",
            "> get current time\n",
            "= datetime.datetime.now().time()\n",
            "< datetime.datetime.time(datetime.datetime.now()) <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1bk8NbnYcsP",
        "colab_type": "code",
        "outputId": "ac2b566a-db8e-4a0b-d619-4dee7c758cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Get all the second values from a list of lists `A`\n",
            "= [row[1] for row in A]\n",
            "< [row[1] for row in A] <EOS>\n",
            "\n",
            "> print a list of integers `list_of_ints` using string formatting\n",
            "= print(', '.join(str(x) for x in list_of_ints))\n",
            "< print(', '.join(str(x) for x in list_of_ints)) <EOS>\n",
            "\n",
            "> cut a string using delimiter '&'\n",
            "= s[:s.rfind('&')]\n",
            "< s[:s.rfind('&')] <EOS>\n",
            "\n",
            "> return dataframe `df` with last row dropped\n",
            "= df.ix[:-1]\n",
            "< df.ix[:-1] <EOS>\n",
            "\n",
            "> Create a dictionary from string `e` separated by `-` and `,`\n",
            "= dict((k, int(v)) for k, v in (e.split(' - ') for e in s.split(',')))\n",
            "< dict((k, int(v)) for k, v in (e.split(' - ') for e in s.split(','))) <EOS>\n",
            "\n",
            "> send data 'HTTP/1.0 200 OK\\r\\n\\r\\n' to socket `connection`\n",
            "= connection.send('HTTP/1.0 200 established\\r\\n\\r\\n')\n",
            "< connection.send('HTTP/1.0 200 established\\r\\n\\r\\n') <EOS>\n",
            "\n",
            "> Get the first and last 3 elements of list `l`\n",
            "= l[:3] + l[-3:]\n",
            "< l[:3] + l[-3:] <EOS>\n",
            "\n",
            "> Print variable `count` and variable `conv` with space string '    ' in between\n",
            "= print(str(count) + '    ' + str(conv))\n",
            "< print(str(count) + '    ' + str(conv)) <EOS>\n",
            "\n",
            "> getting every possible combination of two elements in a list\n",
            "= list(itertools.combinations([1, 2, 3, 4, 5, 6], 2))\n",
            "< list(itertools.combinations([1, 2, 3, 4, 5, 6], 2)) <EOS>\n",
            "\n",
            "> Initialize a pandas series object `s` with columns `['A', 'B', 'A1R', 'B2', 'AABB4']`\n",
            "= s = pd.Series(['A', 'B', 'A1R', 'B2', 'AABB4'])\n",
            "< s = pd.Series(['A', 'B', 'A1R', 'B2', 'AABB4']) <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}